{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LoadingModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5QLOi8BpSeS"
      },
      "source": [
        "# Loading a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1mVJBZOpMxY"
      },
      "source": [
        "import os\n",
        "from os import path\n",
        "import zipfile\n",
        "import re  # RegEx\n",
        "import string\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYMPzcR_paPw",
        "outputId": "848c9f4f-8067-4cd7-802c-5a1ab86482ce"
      },
      "source": [
        "os.listdir('.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'text_classification_model', 'model.zip', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6adt4Rype8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11d993a-1152-46b1-f9d1-86731e2ba2b0"
      },
      "source": [
        "model_name = 'text_classification_model'\n",
        "#\n",
        "if not path.exists(model_name):\n",
        "  # Unzip the model\n",
        "  path_to_zip_file = \"model.zip\"\n",
        "  directory_to_extract_to = \".\"\n",
        "  with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "else:\n",
        "  print(\"Model has already been unzipped\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model has already been unzipped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58fQt0COC0Ty",
        "outputId": "0288cee2-d84d-4193-ef35-3f6238e5efa0"
      },
      "source": [
        "model_path = os.path.join('.', model_name)\n",
        "model_content = os.listdir(model_path) \n",
        "\n",
        "print(\"Model content {}\".format(model_content))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model content ['saved_model.pb', 'variables']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo3rlYYWhVOk",
        "outputId": "4cbc6438-1a4e-4a8e-ad12-4e12db142e1c"
      },
      "source": [
        "print(\"TensorFlow version {}\".format(tf.__version__))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LAZP1SWDS2I"
      },
      "source": [
        "### Now load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdIOnOq-C6mJ",
        "outputId": "aeabb0fb-6ef5-467e-d9bf-269a447d516d"
      },
      "source": [
        "@tf.keras.utils.register_keras_serializable(\n",
        "    package='Custom', name=None\n",
        ")\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')\n",
        "\n",
        "model = None\n",
        "with tf.keras.utils.custom_object_scope({'custom_standardization': custom_standardization}):\n",
        "  model = tf.keras.models.load_model('text_classification_model')  # Folder\n",
        "\n",
        "if model is not None:  \n",
        "  model.summary()\n",
        "else:\n",
        "  print(\"Model not loaded, sorry...\")  \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization_1 (TextVe (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 1)                 160033    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eglnNl4gizBg"
      },
      "source": [
        "## Making predictions with the reconstructed model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqbR3Gm2Di2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467ad0ce-40d3-4779-c24f-7020c7d6713f"
      },
      "source": [
        "examples = [\n",
        "  \"The movie was great!\",\n",
        "  \"The movie was okay.\",\n",
        "  \"The movie was terrible...\",\n",
        "  \"That thing really sucks\",\n",
        "  \"I kind of liked it\",\n",
        "  \"Never seen a better one\",\n",
        "  \"Not really good, not really bad, in my opinion.\",\n",
        "  \"Not really gorgeous\"\n",
        "]\n",
        "\n",
        "predictions = model.predict(examples)\n",
        "print(\"-- Predictions --\")\n",
        "for i in range(len(examples)):\n",
        "    comment = examples[i]\n",
        "    score = predictions[i][0]\n",
        "    review = \"So-so\"\n",
        "    if score < 0.39:\n",
        "        review = \"Very negative review\"\n",
        "    elif score < 0.41:\n",
        "        review = \"Negative review\"\n",
        "    elif score > 0.5:\n",
        "        review = \"Positive review\"\n",
        "    print(\"{} => {} : {}\".format(comment, score, review))\n",
        "print(\"-------------------\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Predictions --\n",
            "The movie was great! => 0.6212304830551147 : Positive review\n",
            "The movie was okay. => 0.4448379576206207 : So-so\n",
            "The movie was terrible... => 0.3627158999443054 : Very negative review\n",
            "That thing really sucks => 0.3784532845020294 : Very negative review\n",
            "I kind of liked it => 0.60201096534729 : Positive review\n",
            "Never seen a better one => 0.550157904624939 : Positive review\n",
            "Not really good, not really bad, in my opinion. => 0.4071146845817566 : Negative review\n",
            "Not really gorgeous => 0.5238542556762695 : Positive review\n",
            "-------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N79_1tXpjSff"
      },
      "source": [
        "### Done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ3c_H9rjUBt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}